<?xml version="1.0" encoding="UTF-8"?>
<refentry version="5.0-subset Scilab" xml:id="filtersd_dense" xml:lang="en"
          xmlns="http://docbook.org/ns/docbook"
          xmlns:xlink="http://www.w3.org/1999/xlink"
          xmlns:svg="http://www.w3.org/2000/svg"
          xmlns:ns3="http://www.w3.org/1999/xhtml"
          xmlns:mml="http://www.w3.org/1998/Math/MathML"
          xmlns:db="http://docbook.org/ns/docbook">

  <refnamediv>
    <refname>filtersd_dense</refname>

    <refpurpose>The NLP solver filterSD for dense Jacobian matrix</refpurpose>
  </refnamediv>

  <refsynopsisdiv>
    <title>Calling Sequence</title>

    <synopsis>[x_out, f_out, ifail, lambda_out, params_out] = filtersd_dense(x0, function, gradient, lower_bounds, upper_bounds, params_in)</synopsis>
  </refsynopsisdiv>

  <refsection>
    <title>Parameters</title>

    <para>Input parameters</para>

    <variablelist>
      <varlistentry>
        <term>x0</term>

        <listitem>
          <para>an estimate of the solution</para>
        </listitem>
      </varlistentry>

      <varlistentry>
        <term>function</term>

        <listitem>
          <para>a function which returns the objective function value and the constraints value</para>
	  <para>The prototype of the function must be:</para>
	  <programlisting role="example"><![CDATA[
[f, c] = function_hs106d(x)
	  ]]></programlisting>
	  <para>An example of such function:</para>
	  <programlisting role="example"><![CDATA[
function [f, c] = function_hs106d(x)
  t = 25.0e-4;

  // objective function
  f = x(1) + x(2) + x(3);
  
  // constraint functions
  c(1) = t*(x(4) + x(6)) - 1.0;
  c(2) = t*(x(5) + x(7) - x(4)) - 1.0;
  c(3) = 1.0e-2*(x(8) - x(5)) - 1.0;
  c(4) = 1.0e2*x(1) + 833.33252*x(4) - x(1)*x(6) - 83333.333;
  c(5) = 125.0e1*(x(5) - x(4)) + x(2)*(x(4) - x(7));
  c(6) = 125.0e4 - 25.0e2*x(5) + x(3)*(x(5) - x(8));
endfunction
	  ]]></programlisting>
        </listitem>
      </varlistentry>

      <varlistentry>
        <term>gradient</term>

        <listitem>
          <para>a function which returns the gradient of the objective function and the gradient of the constraints</para>
	  <para>The prototype of the function must be:</para>
	  <programlisting role="example"><![CDATA[
[a] = function_hs106d(x)
	  ]]></programlisting>
	  <para>An example of such function:</para>
	  <programlisting role="example"><![CDATA[
function a = gradient_hs106d(x)
  t = 25.0e-4;

  //  elements of grad.f and the Jacobian matrix
  a(1,1) = 1;
  a(2,1) = 1;
  a(3,1) = 1;
  a(4,1) = 0;
  a(5,1) = 0;
  a(6,1) = 0;
  a(7,1) = 0;
  a(8,1) = 0;
  
  a(1,2) = 0;
  a(2,2) = 0;
  a(3,2) = 0;
  a(4,2) = t;
  a(5,2) = 0;
  a(6,2) = t;
  a(7,2) = 0;
  a(8,2) = 0;

  a(1,3) = 0;
  a(2,3) = 0;
  a(3,3) = 0;
  a(4,3) = -t;
  a(5,3) = t;
  a(6,3) = 0;
  a(7,3) = t;
  a(8,3) = 0;

  a(1,4) = 0;
  a(2,4) = 0;
  a(3,4) = 0;
  a(4,4) = 0;
  a(5,4) = -1e-2;
  a(6,4) = 0;
  a(7,4) = 0;
  a(8,4) = 1e-2;

  a(1,5) = 1.0e2 - x(6);
  a(2,5) = 0;
  a(3,5) = 0;
  a(4,5) = 833.33252;
  a(5,5) = 0;
  a(6,5) = -x(1);
  a(7,5) = 0;
  a(8,5) = 0;

  a(1,6) = 0;
  a(2,6) = x(4) - x(7);
  a(3,6) = 0;
  a(4,6) = -125.0e1 + x(2);
  a(5,6) = 125.0e1;
  a(6,6) = 0;
  a(7,6) = -x(2);
  a(8,6) = 0;

  a(1,7) = 0;
  a(2,7) = 0;
  a(3,7) = x(5) - x(8);
  a(4,7) = 0;
  a(5,7) = -25.0e2 + x(3);
  a(6,7) = 0;
  a(7,7) = 0;
  a(8,7) = -x(3);
endfunction
	  ]]></programlisting>
        </listitem>
      </varlistentry>

      <varlistentry>
        <term>lower_bounds</term>

        <listitem>
          <para>lower bounds on x and on the constraints</para>
        </listitem>
      </varlistentry>

      <varlistentry>
        <term>upper_bounds</term>

        <listitem>
          <para>lower bounds on x and on the constraints</para>
        </listitem>
      </varlistentry>

      <varlistentry>
        <term>params_in</term>

        <listitem>
          <para>a structure containing the following parameters used to define
          the behavior of solver. Missing elements in the structure take on
          default values, so you only need to set the elements that you wish
          to change from the default.</para>

	  <itemizedlist>
            <listitem>
              <para><emphasis>'rho'</emphasis> - initial trust region radius (typically 10.0)</para>
            </listitem>
            <listitem>
              <para><emphasis>'htol'</emphasis> - tolerance allowed in the sum h(x) of constraint infeasibilities (e.g. 1.0e-6)</para>
            </listitem>
            <listitem>
              <para><emphasis>'rgtol'</emphasis> - tolerance allowed in reduced gradient L2 norm (typically 1.0e-4)</para>
            </listitem>
            <listitem>
              <para><emphasis>'ainfty'</emphasis> - ainfty is used to represent infinity (typically 1.0e20)</para>
            </listitem>
            <listitem>
              <para><emphasis>'ubd'</emphasis> - ubd provides an upper bound on the allowed constraint violation</para>
            </listitem>
            <listitem>
              <para><emphasis>'fmin'</emphasis> - set a strict lower bound on f (x) for feasible x (used to identify an unbounded NLP)</para>
            </listitem>
            <listitem>
              <para><emphasis>'maxit'</emphasis> - maximum number of major iterations allowed</para>
            </listitem>
            <listitem>
              <para><emphasis>'iprint'</emphasis> - verbosity of printing (0=none, 1=one line per iteration, 2=additional text information given)</para>
            </listitem>
            <listitem>
              <para><emphasis>'kmax'</emphasis> - maximum dimension of null space allowed for (kmax &lt;= n)</para>
            </listitem>
            <listitem>
              <para><emphasis>'maxg'</emphasis> - maximum number of reduced gradient vectors stored by the limited memory method (typically 6 or 7)</para>
            </listitem>
            <listitem>
              <para><emphasis>'mlp'</emphasis> - maximum length of arrays used in degeneracy control (typically 50)</para>
            </listitem>
            <listitem>
              <para><emphasis>'mxf'</emphasis> - maximum length of filter arrays (typically 50)</para>
            </listitem>
            <listitem>
              <para><emphasis>'mxgr'</emphasis> - an upper limit (e.g. 100) on the number of gradient calls in mxgr (default=1000000)</para>
            </listitem>
            <listitem>
              <para><emphasis>'mxws'</emphasis> - size of the double workspace array (typically 30000)</para>
            </listitem>
            <listitem>
              <para><emphasis>'mxlws'</emphasis> - size of the integer workspace array (typically 30000)</para>
            </listitem>
	  </itemizedlist>
        </listitem>
      </varlistentry>
    </variablelist>

    <para>Output parameters</para>

    <variablelist>
      <varlistentry>
        <term>x_out</term>

        <listitem>
          <para>The solution found</para>
        </listitem>
      </varlistentry>

      <varlistentry>
        <term>f_out</term>

        <listitem>
          <para>The value of the objective function at x_out</para>
        </listitem>
      </varlistentry>

      <varlistentry>
        <term>ifail</term>

        <listitem>
          <para>An integer indicating the status of the optimizer at the end of the optimization</para>

          <itemizedlist>
            <listitem>
              <para><emphasis>0</emphasis> - successful run</para>
            </listitem>

            <listitem>
              <para><emphasis>1</emphasis> - unbounded NLP (f &lt;= fmin at an htol-feasible point)</para>
            </listitem>

            <listitem>
              <para><emphasis>2</emphasis> - bounds on x are inconsistent</para>
            </listitem>

            <listitem>
              <para><emphasis>3</emphasis> - local minimum of feasibility problem and h &gt; htol (nonlinear constraints are locally inconsistent)</para>
            </listitem>

            <listitem>
              <para><emphasis>4</emphasis> - initial point x has h &gt; ubd (reset ubd or x and re-enter)</para>
            </listitem>

            <listitem>
              <para><emphasis>5</emphasis> - maxit major iterations have been carried out</para>
            </listitem>

            <listitem>
              <para><emphasis>6</emphasis> - termination with rho &lt;= htol</para>
            </listitem>

            <listitem>
              <para><emphasis>7</emphasis> - not enough workspace in ws or lws (see message)</para>
            </listitem>

            <listitem>
              <para><emphasis>8</emphasis> - insufficient space for filter (increase mxf and re-enter)</para>
            </listitem>

            <listitem>
              <para><emphasis>&gt;9</emphasis> - unexpected fail in LCP solver (10 has been added to ifail)</para>
            </listitem>

            <listitem>
              <para><emphasis>10</emphasis> - solution obtained</para>
            </listitem>

            <listitem>
              <para><emphasis>11</emphasis> - unbounded problem (f(x)&lt;fmin has occurred: note grad is not evaluated in this case)</para>
            </listitem>

            <listitem>
              <para><emphasis>12</emphasis> - lower_bounds(i) &gt; upper_bounds(i) for some i</para>
            </listitem>

            <listitem>
              <para><emphasis>13</emphasis> - infeasible problem detected in Phase 1</para>
            </listitem>

            <listitem>
              <para><emphasis>14</emphasis> - line search cannot improve f (possibly increase rgtol)</para>
            </listitem>

            <listitem>
              <para><emphasis>15</emphasis> - mxgr gradient calls exceeded (this test is only carried out at the start of each iteration)</para>
            </listitem>

            <listitem>
              <para><emphasis>16</emphasis> - incorrect setting of m, n, kmax, maxg, mlp, mode or tol</para>
            </listitem>

            <listitem>
              <para><emphasis>17</emphasis> - not enough space in ws or lws</para>
            </listitem>

            <listitem>
              <para><emphasis>18</emphasis> - not enough space in lp (increase mlp)</para>
            </listitem>

            <listitem>
              <para><emphasis>19</emphasis> - dimension of reduced space too large (increase kmax)</para>
            </listitem>

            <listitem>
              <para><emphasis>20</emphasis> - maximum number of unsuccessful restarts taken</para>
            </listitem>

            <listitem>
              <para><emphasis>&gt;20</emphasis> - possible use by later sparse matrix codes</para>
            </listitem>
          </itemizedlist>
        </listitem>
      </varlistentry>

      <varlistentry>
        <term>lambda_out</term>

        <listitem>
          <para>Lagrange multipliers for constraints and bound constraints on variables</para>
        </listitem>
      </varlistentry>

      <varlistentry>
        <term>params_out</term>

	<para>A plist giving some ouputs related to the optimization</para>

	<itemizedlist>
	  <listitem>
	    <para><emphasis>'dnorm'</emphasis> - ﬁnal step length</para>
	  </listitem>
	  
	  <listitem>
	    <para><emphasis>'h'</emphasis> - ﬁnal constraint violation</para>
	  </listitem>
	  
	  <listitem>
	    <para><emphasis>'hJt'</emphasis> - ﬁnal constraint violation for 'N' constraints</para>
	  </listitem>
	  
	  <listitem>
	    <para><emphasis>'hJ'</emphasis> - ﬁnal constraint violation for 'A' and 'Z' constraints</para>
	  </listitem>
	  
	  <listitem>
	    <para><emphasis>'ipeq'</emphasis> - number of active equations</para>
	  </listitem>
	  
	  <listitem>
	    <para><emphasis>'k'</emphasis> - number of free variables</para>
	  </listitem>
	  
	  <listitem>
	    <para><emphasis>'itn'</emphasis> - number of iterations</para>
	  </listitem>
	  
	  <listitem>
	    <para><emphasis>'nft'</emphasis> - total number of function calls</para>
	  </listitem>
	  
	  <listitem>
	    <para><emphasis>'ngt'</emphasis> - total number of gradient calls</para>
	  </listitem>

	  <listitem>
	    <para><emphasis>'cstype'</emphasis> - if ifail = 3, cstype indicates constraints that are
	    infeasible in the L1 solution.</para>
	    <para>cstype(i) = </para>
	    <itemizedlist>
	      <listitem>
		<para><emphasis>'A'</emphasis> - if the lower bound on constraint i is infeasible</para>
	      </listitem>
	      <listitem>
		<para><emphasis>'Z'</emphasis> - if the upper bound is infeasible</para>
	      </listitem>
	      <listitem>
		<para><emphasis>'N'</emphasis> - if feasible</para>
	      </listitem>
	    </itemizedlist>
	  </listitem>
	</itemizedlist>
      </varlistentry>
    </variablelist>

  </refsection>

  <refsection>
    <title>Description</title>

    <para>The NLP solver filterSD for dense Jacobian matrix</para>

    <latex style="display" align="center"><![CDATA[ 
\begin{eqnarray}
\mbox{min}        & f(x) & \\
\mbox{subject to} & l \leq x \leq u & \\
\mbox{and}        & l \leq c(x) \leq u
\end{eqnarray}
]]></latex>

    <para>
      Here f(x) is a given objective function of n variables x, and c(x) is a vector of m constraint functions.
      It is required that these functions are continuously diﬀerentiable at points that satisfy the bounds on x, and that
      the user is able to compute the gradient vector g(x) = f(x) and the Jacobian matrix A(x) = cT.
    </para>
    <para>
      Lower and upper bound constraints on the variables x and the constraint functions c(x) may be supplied.
      There main design aims of the code have been to avoid the use of second derivatives, and to avoid storing
      an approximate reduced Hessian matrix by using a new limited memory spectral gradient approach based on Ritz values.
    </para>
    <para>
      The basic approach is that of Robinson’s method, globalised by using a ﬁlter and trust region.
      The code calls the Linear Constraint Problem (LCP) solver glcpd which has been developed using the Ritz values approach.
    </para>
    <para>
      A generalisation of this idea is used to obtain feasibility in the NLP problem. However it is possible that
      the code might terminate at a locally infeasible point, which is a local minimizer of the L1 sum of general
      constraint infeasibilities h(x), subject to the bounds on the variables.
    </para>
  </refsection>

  <refsection>
    <title>Examples</title>

    <programlisting role="example"><![CDATA[ 
function [f, c] = function_hs106d(x)
  t = 25.0e-4;

  // objective function
  f = x(1) + x(2) + x(3);
  
  // constraint functions
  c(1) = t*(x(4) + x(6)) - 1.0;
  c(2) = t*(x(5) + x(7) - x(4)) - 1.0;
  c(3) = 1.0e-2*(x(8) - x(5)) - 1.0;
  c(4) = 1.0e2*x(1) + 833.33252*x(4) - x(1)*x(6) - 83333.333;
  c(5) = 125.0e1*(x(5) - x(4)) + x(2)*(x(4) - x(7));
  c(6) = 125.0e4 - 25.0e2*x(5) + x(3)*(x(5) - x(8));
endfunction

function a = gradient_hs106d(x)
  t = 25.0e-4;

  //  elements of grad.f and the Jacobian matrix
  a(1,1) = 1;
  a(2,1) = 1;
  a(3,1) = 1;
  a(4,1) = 0;
  a(5,1) = 0;
  a(6,1) = 0;
  a(7,1) = 0;
  a(8,1) = 0;
  
  a(1,2) = 0;
  a(2,2) = 0;
  a(3,2) = 0;
  a(4,2) = t;
  a(5,2) = 0;
  a(6,2) = t;
  a(7,2) = 0;
  a(8,2) = 0;

  a(1,3) = 0;
  a(2,3) = 0;
  a(3,3) = 0;
  a(4,3) = -t;
  a(5,3) = t;
  a(6,3) = 0;
  a(7,3) = t;
  a(8,3) = 0;

  a(1,4) = 0;
  a(2,4) = 0;
  a(3,4) = 0;
  a(4,4) = 0;
  a(5,4) = -1e-2;
  a(6,4) = 0;
  a(7,4) = 0;
  a(8,4) = 1e-2;

  a(1,5) = 1.0e2 - x(6);
  a(2,5) = 0;
  a(3,5) = 0;
  a(4,5) = 833.33252;
  a(5,5) = 0;
  a(6,5) = -x(1);
  a(7,5) = 0;
  a(8,5) = 0;

  a(1,6) = 0;
  a(2,6) = x(4) - x(7);
  a(3,6) = 0;
  a(4,6) = -125.0e1 + x(2);
  a(5,6) = 125.0e1;
  a(6,6) = 0;
  a(7,6) = -x(2);
  a(8,6) = 0;

  a(1,7) = 0;
  a(2,7) = 0;
  a(3,7) = x(5) - x(8);
  a(4,7) = 0;
  a(5,7) = -25.0e2 + x(3);
  a(6,7) = 0;
  a(7,7) = 0;
  a(8,7) = -x(3);
endfunction

lower_bounds = [100,  1000, 1000, 10,  10,  10,  10,  10];
upper_bounds = [10000,10000,10000,1000,1000,1000,1000,1000];
x0           = [5000, 5000, 5000, 200, 350, 150, 225, 425];
lambda       = 1e-2*[1,1,1,1,1,1,1,1];

// Solution and multipliers are:
// x_sol = [579.3167, 1359.943, 5110.071, 182.0174,  295.5985, 217.9799, 286.4162, 395.5979];
// lambda_sol = [1964.046, 5210.645, 5110.092, 8.475914e-03, 9.578792e-03, 0.01];

ainfty = 1e20;

// Initialisation of the bounds for the constraints
lower_bounds = [lower_bounds,   -ainfty, -ainfty, -ainfty, -ainfty, -ainfty, -ainfty];
upper_bounds = [upper_bounds,    0,       0,       0,       0,       0,       0];
lambda       = [lambda, 0.0*[1, 1, 1, 1, 1, 1]];

params_in = init_param();

params_in = add_param(params_in, 'ainfty', 1.0e20);

params_in = add_param(params_in, 'fmin',  -ainfty);
params_in = add_param(params_in, 'ubd',    1.0e5);
params_in = add_param(params_in, 'mlp',    50);
params_in = add_param(params_in, 'mxf',    50);

params_in = add_param(params_in, 'rho',    1.0e2);
params_in = add_param(params_in, 'htol',   1.0e-6);
params_in = add_param(params_in, 'rgtol',  1.0e-4);
params_in = add_param(params_in, 'maxit',  60);
params_in = add_param(params_in, 'iprint', 1);
params_in = add_param(params_in, 'kmax',   length(x0));
params_in = add_param(params_in, 'maxg',   5);
params_in = add_param(params_in, 'mxgr',   1000000);

[x_out, f_out, ifail, lambda_out, params_out] = filtersd_dense(x0,function_hs106d, gradient_hs106d, lower_bounds, upper_bounds, params_in);

printf('ifail = %d\n',ifail)
printf('number of free variables = %d\n',params_out('k'));
printf('number of function and gradient calls = %d, %d\n',params_out('nft'),params_out('ngt'));
printf('f_out = %f\n', f_out);
printf('x_out = '); disp(x_out);
printf('lambda_out = '); disp(lambda_out);

[f_sol, c_sol] = function_hs106d(x_out);

printf('value of the constraints ='); disp(c_sol);
 ]]></programlisting>
</refsection>

  <refsection>
    <title>Authors</title>

    <simplelist type="vert">
      <member>Yann COLLETTE</member>
    </simplelist>
  </refsection>
</refentry>
